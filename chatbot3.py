import streamlit as st
from langchain_openai import ChatOpenAI
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
import asyncio
import json

class ExpertPanelChatbot:
    def __init__(self, openai_api_key: str, experts: dict):
        self.llm = ChatOpenAI(
            model_name="gpt-4o-mini",
            temperature=0.7,
            openai_api_key=openai_api_key
        )
        
        self.experts = experts
        self.expert_chains = self._initialize_expert_chains()
        self.summary_chain = self._initialize_summary_chain()
        
    def _initialize_expert_chains(self) -> dict:
        expert_chains = {}
        expert_prompt_template = """
        ã‚ãªãŸã¯{expert_role}ã¨ã—ã¦ã€ä»¥ä¸‹ã®è³ªå•/ãƒˆãƒ”ãƒƒã‚¯ã«ã¤ã„ã¦å°‚é–€çš„ãªæ„è¦‹ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚
        
        è³ªå•/ãƒˆãƒ”ãƒƒã‚¯: {question}
        
        å›ç­”ã®éš›ã¯ä»¥ä¸‹ã®ç‚¹ã«æ³¨æ„ã—ã¦ãã ã•ã„ï¼š
        - ã‚ãªãŸã®å°‚é–€åˆ†é‡ã®è¦³ç‚¹ã‹ã‚‰ã®åˆ†æã‚’æä¾›ã™ã‚‹ã“ã¨
        - å…·ä½“çš„ãªæ ¹æ‹ ã‚„ä¾‹ã‚’ç¤ºã™ã“ã¨
        - æ½œåœ¨çš„ãªèª²é¡Œã‚„æ©Ÿä¼šã‚’æŒ‡æ‘˜ã™ã‚‹ã“ã¨
        
        å°‚é–€å®¶ã¨ã—ã¦ã®æ„è¦‹:
        """
        
        for expert_id, expert_desc in self.experts.items():
            prompt = PromptTemplate(
                template=expert_prompt_template,
                input_variables=["expert_role", "question"]
            )
            expert_chains[expert_id] = LLMChain(llm=self.llm, prompt=prompt)
        return expert_chains
    
    def _initialize_summary_chain(self) -> LLMChain:
        summary_prompt_template = """
        ä»¥ä¸‹ã¯ç•°ãªã‚‹å°‚é–€å®¶ã‹ã‚‰æä¾›ã•ã‚ŒãŸæ„è¦‹ã§ã™ã€‚ã“ã‚Œã‚‰ã®æ„è¦‹ã‚’çµ±åˆã—ã€ãƒãƒ©ãƒ³ã‚¹ã®å–ã‚ŒãŸåŒ…æ‹¬çš„ãªçµè«–ã‚’å°ãå‡ºã—ã¦ãã ã•ã„ã€‚
        
        å…ƒã®è³ªå•/ãƒˆãƒ”ãƒƒã‚¯: {original_question}
        
        å°‚é–€å®¶ã®æ„è¦‹:
        {expert_opinions}
        
        çµ±åˆã•ã‚ŒãŸçµè«–:
        1. ä¸»ãªåˆæ„ç‚¹
        2. é‡è¦ãªæ‡¸å¿µäº‹é …
        3. æ¨å¥¨ã•ã‚Œã‚‹ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
        4. è¿½åŠ ã§æ¤œè¨ãŒå¿…è¦ãªç‚¹
        
        çµè«–:
        """
        
        summary_prompt = PromptTemplate(
            template=summary_prompt_template,
            input_variables=["original_question", "expert_opinions"]
        )
        return LLMChain(llm=self.llm, prompt=summary_prompt)
    
    async def get_expert_opinion(self, expert_id: str, expert_desc: str, question: str, progress_placeholder) -> str:
        """å€‹ã€…ã®å°‚é–€å®¶ã®æ„è¦‹ã‚’å–å¾—ã—ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§è¡¨ç¤ºã™ã‚‹"""
        response = await self.expert_chains[expert_id].arun(
            expert_role=expert_desc,
            question=question
        )
        progress_placeholder.write(f"ğŸ’¡ **{expert_id.replace('_', ' ').title()}ã®æ„è¦‹:**")
        progress_placeholder.markdown(response)
        return response
    
    async def get_integrated_response(self, question: str, progress_placeholder) -> tuple:
        """å°‚é–€å®¶ã®æ„è¦‹ã‚’åé›†ã—ã€çµ±åˆã•ã‚ŒãŸå›ç­”ã‚’ç”Ÿæˆã™ã‚‹"""
        expert_opinions = {}
        
        # éåŒæœŸã§å„å°‚é–€å®¶ã®æ„è¦‹ã‚’å–å¾—
        tasks = []
        for expert_id, expert_desc in self.experts.items():
            task = self.get_expert_opinion(expert_id, expert_desc, question, progress_placeholder)
            tasks.append(task)
        
        # ã™ã¹ã¦ã®æ„è¦‹ã‚’åé›†
        opinions = await asyncio.gather(*tasks)
        expert_opinions = dict(zip(self.experts.keys(), opinions))
        
        # æ„è¦‹ã‚’çµ±åˆ
        formatted_opinions = "\n\n".join([
            f"{expert_id.upper()}ã®æ„è¦‹:\n{opinion}"
            for expert_id, opinion in expert_opinions.items()
        ])
        
        progress_placeholder.write("ğŸ“Š **çµ±åˆã•ã‚ŒãŸçµè«–ã‚’ç”Ÿæˆä¸­...**")
        final_response = await self.summary_chain.arun(
            original_question=question,
            expert_opinions=formatted_opinions
        )
        
        return final_response, expert_opinions

def init_session_state():
    if 'messages' not in st.session_state:
        st.session_state.messages = []
    if 'chatbot' not in st.session_state:
        st.session_state.chatbot = None
    if 'experts' not in st.session_state:
        st.session_state.experts = {
            "business_analyst": "ãƒ“ã‚¸ãƒã‚¹ã‚¢ãƒŠãƒªã‚¹ãƒˆã€‚å¸‚å ´åˆ†æã€åç›Šæ€§ã€ãƒ“ã‚¸ãƒã‚¹æˆ¦ç•¥ã®è¦³ç‚¹ã‹ã‚‰åˆ†æã‚’è¡Œã†ã€‚",
            "tech_expert": "æŠ€è¡“å°‚é–€å®¶ã€‚æŠ€è¡“çš„ãªå®Ÿç¾å¯èƒ½æ€§ã€å¿…è¦ãªãƒªã‚½ãƒ¼ã‚¹ã€é–‹ç™ºæœŸé–“ã«ã¤ã„ã¦åˆ†æã‚’è¡Œã†ã€‚",
            "risk_manager": "ãƒªã‚¹ã‚¯ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã€‚æ³•çš„ãƒªã‚¹ã‚¯ã€ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒªã‚¹ã‚¯ã€é‹ç”¨ãƒªã‚¹ã‚¯ã‚’è©•ä¾¡ã™ã‚‹ã€‚",
            "customer_advocate": "ã‚«ã‚¹ã‚¿ãƒãƒ¼ã‚¢ãƒ‰ãƒœã‚±ã‚¤ãƒˆã€‚é¡§å®¢è¦–ç‚¹ã§ã®ä¾¡å€¤ã€ä½¿ã„ã‚„ã™ã•ã€éœ€è¦ã‚’è©•ä¾¡ã™ã‚‹ã€‚"
        }

def expert_manager():
    """å°‚é–€å®¶ã®è¨­å®šã‚’ç®¡ç†ã™ã‚‹UI"""
    st.subheader("å°‚é–€å®¶ã®è¨­å®š")
    
    # å°‚é–€å®¶ã®è¿½åŠ 
    with st.expander("å°‚é–€å®¶ã‚’è¿½åŠ "):
        col1, col2 = st.columns(2)
        with col1:
            new_expert_id = st.text_input("å°‚é–€å®¶IDï¼ˆè‹±æ•°å­—ï¼‰", key="new_expert_id")
        with col2:
            new_expert_desc = st.text_area("å°‚é–€å®¶ã®èª¬æ˜", key="new_expert_desc")
        
        if st.button("è¿½åŠ ", key="add_expert"):
            if new_expert_id and new_expert_desc:
                st.session_state.experts[new_expert_id] = new_expert_desc
                st.success(f"å°‚é–€å®¶ã€Œ{new_expert_id}ã€ãŒè¿½åŠ ã•ã‚Œã¾ã—ãŸï¼")
    
    # æ—¢å­˜ã®å°‚é–€å®¶ã®ç®¡ç†
    with st.expander("å°‚é–€å®¶ã‚’ç®¡ç†"):
        for expert_id, expert_desc in list(st.session_state.experts.items()):
            st.markdown(f"**{expert_id}**")
            new_desc = st.text_area("èª¬æ˜", value=expert_desc, key=f"edit_{expert_id}")
            cols = st.columns([1, 1])
            with cols[0]:
                if st.button("æ›´æ–°", key=f"update_{expert_id}"):
                    st.session_state.experts[expert_id] = new_desc
                    st.success("æ›´æ–°ã•ã‚Œã¾ã—ãŸï¼")
            with cols[1]:
                if st.button("å‰Šé™¤", key=f"delete_{expert_id}"):
                    del st.session_state.experts[expert_id]
                    st.warning("å‰Šé™¤ã•ã‚Œã¾ã—ãŸï¼")
    
    # è¨­å®šã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ/ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
    with st.expander("è¨­å®šã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ/ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"):
        # ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
        export_data = json.dumps(st.session_state.experts, indent=2, ensure_ascii=False)
        st.download_button(
            label="è¨­å®šã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ",
            data=export_data,
            file_name="expert_settings.json",
            mime="application/json"
        )
        
        # ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
        uploaded_file = st.file_uploader("è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ", type="json")
        if uploaded_file is not None:
            try:
                imported_experts = json.load(uploaded_file)
                st.session_state.experts = imported_experts
                st.success("è¨­å®šãŒã‚¤ãƒ³ãƒãƒ¼ãƒˆã•ã‚Œã¾ã—ãŸï¼")
            except Exception as e:
                st.error(f"ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {str(e)}")

async def main():
    st.title("ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºå¯èƒ½ãªå°‚é–€å®¶ãƒ‘ãƒãƒ«ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ ğŸ¤–")
    
    init_session_state()
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§è¨­å®š
    with st.sidebar:
        st.header("è¨­å®š")
        api_key = st.text_input("OpenAI APIã‚­ãƒ¼", type="password")
        if api_key:
            st.success("APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¾ã—ãŸï¼")
        
        # å°‚é–€å®¶ã®ç®¡ç†UIã‚’è¡¨ç¤º
        expert_manager()
    
    # ãƒ¡ã‚¤ãƒ³ã®ãƒãƒ£ãƒƒãƒˆã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
    for message in st.session_state.messages:
        if message["role"] == "user":
            st.chat_message("user").write(message["content"])
        else:
            with st.chat_message("assistant"):
                st.write(message["content"])
    
    # ãƒãƒ£ãƒƒãƒˆå…¥åŠ›
    if prompt := st.chat_input("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"):
        if not api_key:
            st.error("OpenAI APIã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„ï¼")
            return
        
        if not st.session_state.experts:
            st.error("å°‘ãªãã¨ã‚‚1äººã®å°‚é–€å®¶ã‚’è¨­å®šã—ã¦ãã ã•ã„ï¼")
            return
        
        st.session_state.messages.append({"role": "user", "content": prompt})
        st.chat_message("user").write(prompt)
        
        with st.chat_message("assistant"):
            progress_placeholder = st.empty()
            
            # æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆï¼ˆæœ€æ–°ã®å°‚é–€å®¶è¨­å®šã‚’åæ˜ ï¼‰
            chatbot = ExpertPanelChatbot(api_key, st.session_state.experts)
            
            # å°‚é–€å®¶ã®æ„è¦‹ã‚’å–å¾—ã—ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§è¡¨ç¤º
            response, expert_opinions = await chatbot.get_integrated_response(prompt, progress_placeholder)
            
            # æœ€çµ‚çš„ãªçµ±åˆçµè«–ã‚’è¡¨ç¤º
            st.write("ğŸ¯ **æœ€çµ‚çš„ãªçµ±åˆçµè«–:**")
            st.write(response)
            
            st.session_state.messages.append({
                "role": "assistant",
                "content": response
            })

if __name__ == "__main__":
    asyncio.run(main())